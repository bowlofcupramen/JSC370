---
title: "Lab 04 - Data Visualization and GAMs"
format:
  html:
    embed-resources: true
jupyter: python3
---

```{python}
#| label: setup
#| message: false
#| warning: false
import pandas as pd
import numpy as np
from plotnine import *
import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt
from pygam import LinearGAM, s
import statsmodels.api as sm
from folium.plugins import MarkerCluster
```

# Learning Goals

- Read in and prepare the meteorological dataset
- Use `pd.merge()` to join two datasets
- Deal with missings and impute data
- Create several graphs with different `geoms` in `plotnine`
- Create a facet graph
- Conduct customizations of the graphs
- Fit smooth regression models using `pygam` and compare to a linear regression model

# Lab Description

We will work with the meteorological data from last week's lab.

**The objective of the lab is to examine the association between weather variables in the US, practice data visualization, and fit smooth regression models.**


### 1. Read in the data

First download and then read in with pandas:

```{python}
url = "https://raw.githubusercontent.com/JSC370/JSC370-2026/main/data/met_all_2025.gz"
met = pd.read_csv(url, compression="gzip")
```

### 2. Prepare the data: some wrangling

- From last week: remove temperatures less than -20C and change 999.9 to NaN.
- Generate a date variable using `pd.to_datetime()`.
- Using date filtering, keep the observations of the first week of July 2025.
- Compute the mean by station of the variables `temp`, `rh`, `wind_sp`, `vis_dist`, `dew_point`, `lat`, `lon`, and `elev`.
- Create a region variable for NW, SW, NE, SE based on lon = -98.00 and lat = 39.71 degrees.
- Create a categorical variable for elevation (low: < 252m, high: >= 252m)

```{python}
# Replace 999.9 with NaN and filter temps > -20
met.loc[met['temp'] == 999.9, 'temp'] = np.nan
met = met[met['temp'] > -20].copy()

# Create date variable
met['date'] = pd.to_datetime(
    met[['year', 'month', 'day', 'hour']])

# Create region variable using np.select
met['region'] = (
    np.select(
        [
            (met['lon'] < -98) & (met['lat'] >= 39.71),
            (met['lon'] >= -98) & (met['lat'] >= 39.71),
            (met['lon'] < -98) & (met['lat'] < 39.71),
        ],
        ['NW', 'NE', 'SW'],
        default='SE'
    )
)

# Create elevation category
met['elev_high_low'] = np.select(
    [met['elev'] >= 252],
    ['high'],
    default='low'
)

display(met.head())
```



### 3. Use `geom_violin` to examine `dew_point` for low and high elevations by region

Use `geom_violin` and subset the data to the first two weeks in July.

- Subset to the first two weeks in July
- Use facets
- Summarize below

```{python}
# Subset to first two weeks of July
met_july = met[(met['date'] >= '2025-07-01') & (met['date'] < '2025-07-15')].copy()

# Create violin plot with facets
(ggplot(met_july,
        aes(x='elev_high_low', y='dew_point', fill='elev_high_low')) +
  geom_violin() +
  facet_wrap('~region') +
  labs(x='Elevation Category', y='Dew Point Temperature',
       title='Dew Point by Elevation and Region (July 1-14)') +
  theme_minimal())

```

Summary:
In the west, especially for the high elevation points, there is more variance in the dew point. 
It also appears that in the southern regions, the dew point is in general higher than in the north.
In the east, southern regions have much less variance in their dew points than the north. 
Also, the southwest has a bimodal shape, especially for the low elevation, unliek the other regions.

### 4. Use `geom_bar` to create barplots of the proportion of weather stations by elevation category colored by region

- Use the subset data from \#3, the first two weeks of July
- Create nice labels on axes and add a title
- Try a second plot with counts and `dodge` positioning
- Summarize below

```{python}
# Proportion barplot (position='fill')
(ggplot(met_july,
        aes(x='elev_high_low', fill='region')) +
  geom_bar(position='fill') +
  scale_fill_brewer(type='qual', palette='Set2') +
  labs(x='Elevation Category', y='Proportion of Stations',
       title='Proportion of Weather Stations by Elevation and Region') +
  theme_minimal())
```

```{python}
# Count barplot with dodge positioning
(ggplot(met_july,
        aes(x='elev_high_low', fill='region')) +
  geom_bar(position='dodge') +
  scale_fill_brewer(type='qual', palette='Set2') +
  labs(x='Elevation Category', y='Proportion of Stations',
       title='Proportion of Weather Stations by Elevation and Region') +
  theme_minimal())

```

Summary:
For high elevations, the northeast region has the most, while the other 3 regions have roughly the same amount (relatively), with northwest, southeast, and southwest being the other regions in order of increasing stations. 

For low elevations, most are in the southeast region, with some being in the northeast, and very little being in the western regions.

### 5. Use `stat_summary` to examine mean dew point by region with standard deviation error bars

- Use `stat_summary` with appropriate functions for mean and standard deviation
- Add error bars using another layer of `stat_summary` with `geom = "errorbar"`
- Use `coord_flip`
- Add labels and a title
- Summarize below

```{python}
# Use stat_summary with fun_y, fun_ymin, fun_ymax
# Hint: fun_ymin=lambda x: np.mean(x) - np.std(x)

(ggplot(met_july, aes(x='region', y='dew_point')) +
  stat_summary(fun_y=np.mean,
               fun_ymin=lambda x: np.mean(x) - np.std(x),
               fun_ymax=lambda x: np.mean(x) + np.std(x),
               geom='errorbar') +
  coord_flip() +
  labs(x='Region', y='Dew Point Temperature',
       title='Dew Point Temperature by Region') +
  theme_minimal())
```

Summary:
The western regions tend to have a lower dew point temperature and a higher standard deviation than the eastern regions. 
In particular, the southwest region has the greatest standard deviation and the southeast has the least.
As for mean dew point temperature, the northwest has the lowest while the southeast has the highest.


### 6. Smooth Regression with GAMs

Let's practice running regression models with smooth functions on X. We use the `statsmodels` OLS for linear models and `pygam` package and `LinearGAM` function to do this.

- Use the subsetted data. First remove NaN before fitting
- Fit both a linear model with `sm.OLS` and a spline model (use `LinearGAM()` with `s()` for a smooth term on wind_sp and temp).
- For the spline model try `n_splines` = 20
- Summarize and plot the results from the models.

```{python}
# Data prep
# Remove NaN values before fitting
met_clean = met_july.dropna(subset=['wind_sp', 'temp', 'dew_point'])

X = met_clean[['wind_sp', 'temp']].values
y = met_clean['dew_point'].values
```

- Now fit linear model with sm.OLS

```{python}
# Don't forget to add a constant
X_const = sm.add_constant(X)

linear_mod = sm.OLS(y, X_const).fit()
print("Linear Model:")
print(linear_mod.summary())
```

Summary:

- Report adjusted R2
- Are the beta coefficients for wind speed and temperature significant?

Adjusted R2 is 0.115.
It differs from the regular R2 simply vy the fact that the adjusted one accounts for the number of features.

The coefficients are indeed significant based on the p values in the table, which are all 0 when rounded to 3 decimal points. 


```{python}
# GAM spline model
# Use LinearGAM with s() for smooth terms
# s(0) refers to first column, s(1) to second column

gam_mod = LinearGAM(
    s(0, n_splines=20) +
    s(1, n_splines=20)).fit(X, y)
print("\nSmooth Spline Model:")
print(gam_mod.summary())
```

Summary:

- Report pseudo R2, how does it compare to the linear model R2?
- What are the EDoF for wind speed and temp?
- Are the smooths for wind speed and temperature significant?

The pseudo R2 is 0.2868, which is a much higher R2 than the one from the linear model, which is 0.115.

The EDoF for wind speed is 13.5 and the EDoF for temp is 16.9. The overall EDoF is 30.3714, which appears to be a sum of the EDoF for wind wpeed and temp. The model is highly non-linear.

Yes, the smooths are indeed significant, based on the low p values, both of which are many magnitudes less than 0.05. 

```{python}
#| fig-align: center
# Plot partial dependence curves for each predictor

# define the figure size
fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# define the variables and colors
spec = [
    (0, 0, "Wind Speed",  "blue", "Effect of Wind Speed"),
    (1, 1, "Temperature", "red",  "Effect of Temperature"),
]

# loop over smooth variables
for ax, (term, xcol, xlabel, color, title) in zip(axes, spec):
    XX = gam_mod.generate_X_grid(term=term)
    x = XX[:, xcol]
    pd_effect = gam_mod.partial_dependence(term=term, X=XX)
    _, ci = gam_mod.partial_dependence(term=term, X=XX, width=0.95)

    ax.plot(x, pd_effect, color=color, lw=2)
    ax.plot(x, ci, color=color, ls="--", lw=1)
    ax.set(xlabel=xlabel, ylabel="Partial Effect on Dew Point", title=title)

plt.tight_layout()
plt.show()
```

Summary:

- Visual inspection of the fitted curves
- Does the smooth term capture meaningful non-linearity?

The smooth term indeed captures meaningful non-linearity.

Based on the previous points, the high, statistically significant EDoF already indicates meaningful non-linearity.

The two plots generated here just now further demonstrates this since both plots are non-linear. 

However, it is interesting to note that the temperature appears to be roughly linear for a large section of the graph.

Despite this, the graphs are ultimately non-linear, especially so for wind speed.